{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Seb125/MFCC_Genres/blob/main/Genres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engeneering: Calculating mfcc's for each audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import math\n",
    "import json\n",
    "\n",
    "DATASET_PATH = \"Genres\"\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "\n",
    "# json_path: path to the file where we store all mfccs and the labels\n",
    "# each track is chopped into 10 segments\n",
    "\n",
    "def save_mfcc(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=10):\n",
    "    \n",
    "    # dictionary to store data\n",
    "    data = {\n",
    "      \"mapping\": [], # classical is mapped to indice 0\n",
    "      \"mfcc\": [], # mfccs for each segment\n",
    "      \"labels\":[]  # target (first segment is classical, second, classical....)\n",
    "\n",
    "    }\n",
    "    \n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length)\n",
    "    \n",
    "    # loop through all the genres\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        # esnure that we're not at the root/dataset level\n",
    "        if dirpath is not dataset_path:   #dirpath gives path of current directory\n",
    "            \n",
    "            # save the semantic label\n",
    "            dirpath_components = dirpath.split(\"/\") # genre/blues => [\"genre\", \"blues\"]\n",
    "            semantic_label = dirpath_components[-1]  # last entry of dirpath_components\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing {}\".format(semantic_label))\n",
    "\n",
    "            # process files for a specific genre\n",
    "            for f in filenames:\n",
    "                \n",
    "                #load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                print(file_path)\n",
    "                signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                \n",
    "                # process segments extracting mfcc and storing data\n",
    "                for s in range(num_segments):\n",
    "                    start_sample = num_samples_per_segment * s # s = 0 -> 0\n",
    "                    finish_sample = start_sample + num_samples_per_segment # s = 0 -> num_samples_per_segment\n",
    "\n",
    "          \n",
    "                    mfcc = librosa.feature.mfcc(signal[start_sample:finish_sample],\n",
    "                                                      sr=sr,\n",
    "                                                      n_fft=n_fft,\n",
    "                                                      n_mfcc=n_mfcc,\n",
    "                                                      hop_length=hop_length)\n",
    "                    \n",
    "                    mfcc = mfcc.T  # transpose -> mfcc vectors are columns\n",
    "                    \n",
    "                    \n",
    "                    # store mfcc for segment if it has the expected length\n",
    "                    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1) # cause the first iteration is at the root level\n",
    "                        print(\"{}, segment:{}\".format(file_path, s))\n",
    "   \n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different classifiers (MLP, SVM, KNN) on the flattened feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "DATASET_PATH = \"data10.json\"\n",
    "\n",
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp: # r = read\n",
    "        data = json.load(fp)\n",
    "        \n",
    "    # convert lists into numpy arrays\n",
    "    inputs = np.array(data[\"mfcc\"])\n",
    "    targets = np.array(data[\"labels\"])\n",
    "\n",
    "    return inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "inputs, targets = load_data(DATASET_PATH)\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening and Normalizing Input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reshape inputs: Inputs have 3 dimensions (0:segments, 1:mfcc windows in each segment, 2:mff vectors)\n",
    "# for each segment we concatenate all mfcc vectors\n",
    "\n",
    "# inputs_train.shape = (699, 130, 13) inputs_train_reshaped.shape = (699, 1690)\n",
    "X_train_reshaped = X_train.reshape(699,1690)\n",
    "# inputs_train.shape = (300, 130, 13) inputs_train_reshaped.shape = (300, 1690)\n",
    "X_test_reshaped = X_test.reshape(300,1690)\n",
    "\n",
    "# normalizing input features\n",
    "X_train = StandardScaler().fit_transform(X_train_reshaped)\n",
    "X_test = StandardScaler().fit_transform(X_test_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input vectors live in $R^{1690}$, which is quite high dimensional compared to the number of samples (900). This is a scenario where kernel methods are of great use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel methods (https://bloom.bg/2ui2T4q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Mapping from an input space $\\chi$ to a vector in $R^d$ is called feature extraction.  \n",
    "Feature mapping is a function of the form $\\psi: \\chi -> R^d$.  \n",
    "To get expressive hypothesis spaces using linear models we need high-dimensional feature spaces. Suppose we start with $x= (1, x_1, ..., x_d) \\in R^{d+1} = \\chi$. Now with our feature mapping $\\psi(x)$ we want all monomials of degree M. Then we will end up with the number of features of $O(d^M)$?. Thus we will get extremely large matrices. Having large feature spaces have two problems, Overfitting (handled by regularization) and memory, computational cost. Kernel methods can (sometimes) help with memory and computational costs.\n",
    "\n",
    "\n",
    "###### Definition\n",
    "\n",
    "A method can be kernalized if inputs appear inside inner products: $\\langle  \\; \\psi(x), \\psi(x') \\; \\rangle$ for $x, x' \\in \\chi$.  \n",
    "The kernel function corresponding to such an inner product is:  \n",
    "\n",
    "$k(x,x') = \\langle  \\; \\psi(x), \\psi(x') \\; \\rangle$.  \n",
    "\n",
    "Kernels as similarity scores: It is often useful to think of the kernel function as a similarity score. The final classifier is a similarity-weighted vote (see section... for details). However this is not a mathematically precise statement.\n",
    "\n",
    "\n",
    "\n",
    "###### Different Kernels\n",
    "\n",
    "###### Linear Kernel\n",
    "\n",
    "Feature map: $\\phi(x)  = x$  \n",
    "Kernel: $k(x, x') = x^Tx'$\n",
    "\n",
    "A linear kernel uses just the original input features. The output of the linear kernel function just gives the standard dot product between two data points $x^Tx'$. As x and x' lie in the original input space,w e don't get acces to a higher dimensional feature space by using a lienar kernel. We are using the original feature space and the kernel function does not has any computational benefits. So if our input vector already lie in high dimensional feature space, such that the data is already seperable with a linear method, I won't get any benefit form using kernel methods.(?)\n",
    "\n",
    "###### Quadratic Kernel\n",
    "\n",
    "Input space $\\chi = R^d$  \n",
    "Feature space: $H = R^D$, where $D = d + \\binom{d}{2} \\approx \\frac{d^2}{2}$.\n",
    "\n",
    "Feature map: \n",
    "\n",
    "$\\psi(x) = (x_1,...,x_d,x^2_1,...x^2_d,\\sqrt{2}x_1x_2,...,\\sqrt{2}x_{d-1}x_d)^T$\n",
    "\n",
    "Then for $\\forall x, x' \\in R^d$\n",
    "\n",
    "$k(x,x') = \\langle  \\; \\psi(x), \\psi(x') \\; \\rangle = \\langle  \\; x, x' \\; \\rangle + \\langle  \\; x, x' \\; \\rangle ^2$\n",
    "\n",
    "Computation for inner product with explicit mapping: $O(d^2)$  \n",
    "Computation for implicit kernel calculation: $O(d)$.\n",
    "\n",
    "Thus with the qudratic kernel function we can evaluate a dot product of feature space that includes all monomials up to degree 2 of the original input space, while computation cost is in the same order as for the original feature space. Notice that we have these extra coefficients ($\\sqrt{2}$) in front of our features. These interact with our regularization. We can use smaller coefficients $w$ to get the same output, such that with regularization these features get favored by the model.\n",
    "\n",
    "###### Polynomial Kernel\n",
    "\n",
    "Input space $\\chi = R^d$  \n",
    "Kernel function:  \n",
    "\n",
    "$k(x,x') = (1 + \\langle  \\; x, x' \\; \\rangle)^M$\n",
    "    \n",
    "Corresponds to a feature map with all monomials up to degree M.  \n",
    "For any M, computing the kernel has same computationsl cost.  \n",
    "Cost of explicit inner product computation grows rapidly in M. \n",
    "\n",
    "###### RBF/Gaussian Kernel\n",
    "\n",
    "Input space $\\chi = R^d$   \n",
    "Kernel function:  \n",
    "\n",
    "$k(x,x') = exp(-\\frac{||x-x'||^2}{2\\sigma^2})$ \n",
    "\n",
    "where $\\sigma^2$ is known as the bandwith parameter. \n",
    "\n",
    "Does it act like a similarity score?:\n",
    "For $x=x'$ the kernel evaluates to 1 and for increasing distance between x and x' the value of the functions gets closer to 0.  \n",
    "Why \"radial\"?: The output is independent of orientation. All x's in the same radius of x get the same similarity score.  \n",
    "For the RBF kernel we have in some sense departed form our \"inner product of feature vector\" recipe. The RBF kernel corresponds to an infinite dimensional feature vector ($\\psi(x)$ has infinite number of dimensions). \n",
    "It is probably the most common nonlinear kernel. \n",
    "How does the kernel function behave if we change $\\sigma^2$?:....see UCSD lecture slides!\n",
    "\n",
    "###### The Kernel trick\n",
    "\n",
    "We can transform certain objektive functions into a kernalized version (see details below). This kernalized objective function contains the kernel matrix.\n",
    "\n",
    "For points $x_1,...,x_n \\in \\chi$ and an inner product $\\langle  \\; .,. \\; \\rangle$ on $\\chi$, the kernel matrix is defined as:  \n",
    "\n",
    "$K = (\\langle  \\; x_i, x_j \\; \\rangle)_{ij} = \\left(\\begin{array}{rrr} \n",
    "\\langle  \\; x_1, x_1 \\; \\rangle & ... & \\langle  \\; x_1, x_n \\; \\rangle \\\\ \n",
    "... & ... & ... \\\\ \n",
    "\\langle  \\; x_n, x_1 \\; \\rangle & ... & \\langle  \\; x_n, x_n \\; \\rangle \\\\ \n",
    "\\end{array}\\right) = XX^T$  \n",
    "\n",
    "which is an $nxn$ matrix. \n",
    "\n",
    "Given a kernalized ML algorithm, we can swap out the kernel function. The new kernel may correspond to a high dimensional feature space. Once the kernel matrix is computed , the computational cost depends only on the number of data points, rather than the dimesnion of the feature space. \n",
    "\n",
    "In ridge regression we deel with a matrix $X^TX$ which is $dxd$. In general you would prefer to work with the smaller matrix. Thus kernel methods are prefered when $n<<d$.\n",
    "\n",
    "Swapping out a linear kernel for a new kernel is called the kernel trick.\n",
    "\n",
    "\n",
    "### How to kernalize an objective function\n",
    "\n",
    "#### Generalized objective function\n",
    "\n",
    "Featurized SVM objective:\n",
    "\n",
    "$min_{w\\in R^d} \\frac{1}{2} ||w||^2 + \\frac{c}{n} \\Sigma_{i=1}^{n} max(0, 1 - y_i[\\langle  \\; w, \\psi(x_i) \\; \\rangle])$\n",
    "\n",
    "Generalized objective:\n",
    "\n",
    "$min_{w\\in H}  R(||w||) + L(\\langle  \\; w, \\psi(x_1) \\; \\rangle, .... , \\langle  \\; w, \\psi(x_n) \\; \\rangle)$,\n",
    "\n",
    "where\n",
    "\n",
    "$R: R^{>=0} -> R$ in nondecreasing (Regularization term)  \n",
    "$L: R^n -> R$ is arbitrary (Loss term)   \n",
    "with Hilbert space $H$, typically $H = R^d$\n",
    "\n",
    "Ridge regression and SVM are of this form.  \n",
    "Lasso regression is not of this form, as $l_1$ does not correspond to an inner product (Why is this important? see section....).\n",
    "\n",
    "#### Representer Theorem\n",
    "\n",
    "Let $min_{w\\in H}  R(||w||) + L(\\langle  \\; w, \\psi(x_1) \\; \\rangle, .... , \\langle  \\; w, \\psi(x_n) \\; \\rangle)$.\n",
    "\n",
    "If J(w) has a minimizer, then it has a minimizer of the form $w^* = \\Sigma_{i=1}^{n} \\alpha_i \\psi(x_i)$. Thus $w^*$ lies in the span of the data; is a linear combination of the featurized input vectors.\n",
    "\n",
    "Proof\n",
    "\n",
    "Let w be a minimizer  \n",
    "Let $M = span(\\langle  \\; w, \\psi(x_1) \\; \\rangle, .... , \\langle  \\; w, \\psi(x_n) \\; \\rangle)$  \n",
    "Let $w^*= Proj_M w$. So $\\exists$ s.t. $w^* = \\Sigma_{i=1}^{n} \\alpha_i \\psi(x_i)$  \n",
    "$w^*$ lives in $R^d$ but it lives also in M, which is a subspace of $R^d$ of dimension n.  \n",
    "$w^{\\bot} := w - w^*$ is orthogonal to M.  \n",
    "Projections decrease norms: $||w^*|| \\leq ||w||$  \n",
    "Since R is nondecreasing, $R(||w^*||) \\leq R(||w||)$  \n",
    "\n",
    "$\\langle  \\; w, \\psi(x_i) \\; \\rangle = \\langle  \\; w^* + w - w^*, \\psi(x_i) \\; \\rangle = \\langle  \\; w^* + w^{\\bot}, \\psi(x_i) \\; \\rangle = \\langle  \\; w^*, \\psi(x_i) \\; \\rangle + \\langle  \\; w^{\\bot}, \\psi(x_i) \\; \\rangle\n",
    "= \\langle  \\; w^*, \\psi(x_i) \\; \\rangle$  \n",
    "\n",
    "So $L(\\langle  \\; w, \\psi(x_i) \\; \\rangle) = L(\\langle  \\; w^*, \\psi(x_i) \\; \\rangle)$  \n",
    "\n",
    "$J(w^*) \\leq J(w)$\n",
    "\n",
    "Therefore $w^* = \\Sigma_{i=1}^{n} \\alpha_i \\psi(x_i)$ is also a minimizer.\n",
    "\n",
    "\n",
    "#### Kernalized predictions\n",
    "\n",
    "Consider $w^* = \\Sigma_{i=1}^{n} \\alpha_i \\psi(x_i)$ (In he following w is used, but I refer to $w^*$ as described in the representer theorem).  \n",
    "\n",
    "How do we make predictions for a given $x \\in \\chi$?  \n",
    "\n",
    "$f(x) = \\langle  \\; w, \\psi(x) \\; \\rangle = \\langle  \\; \\Sigma_{i=1}^{n} \\alpha_i \\psi(x_i), \\psi(x) \\; \\rangle = \\Sigma_{i=1}^{n} \\alpha_i \\langle  \\; \\psi(x_i), \\psi(x) \\; \\rangle = \\Sigma_{i=1}^{n} \\alpha_i k(x_ix)$\n",
    "\n",
    "Predictions on training points $x_1$ to $x_n$:  \n",
    "\n",
    "$ \\left(\\begin{array}{r} \n",
    "f(x_1) \\\\ \n",
    "... \\\\ \n",
    "f(x_n)\\\\ \n",
    "\\end{array}\\right) = \\left(\\begin{array}{r} \n",
    "\\Sigma_{i=1}^{n} \\alpha_i k(x_ix_1) \\\\ \n",
    "... \\\\ \n",
    "\\Sigma_{i=1}^{n} \\alpha_i k(x_ix_n)\\\\ \n",
    "\\end{array}\\right)= \\left(\\begin{array}{r} \n",
    "\\alpha_1k(x_1x_1) + ... + \\alpha_nk(x_1x_n) \\\\ \n",
    "... \\\\ \n",
    "\\alpha_1k(x_nx_1) + ... + \\alpha_nk(x_nx_n)\\\\ \n",
    "\\end{array}\\right) = \\left(\\begin{array}{r} \n",
    "k(x_1x_1) + ... + k(x_1x_n) \\\\ \n",
    "... \\\\ \n",
    "k(x_nx_1) + ... + k(x_nx_n)\\\\ \n",
    "\\end{array}\\right) \\left(\\begin{array}{r} \n",
    "\\alpha_1\\\\ \n",
    "... \\\\ \n",
    "\\alpha_n\\\\ \n",
    "\\end{array}\\right) = K\\alpha$  \n",
    "\n",
    "Note: f(x) is a linear combination of $k(x_1,x),...,k(x_n,x)$, all considered functions of x.  \n",
    "\n",
    "\n",
    "#### Kernalized regularization\n",
    "\n",
    "Consider $w = \\Sigma_{i=1}^{n} \\alpha_i \\psi(x_i)$. What does $R(||w||)$ look like?  \n",
    "\n",
    "$||w||^2 = \\langle  \\; w, w \\; \\rangle = \\langle  \\; \\Sigma_{i=1}^{n} \\alpha_i \\psi(x_i), \\Sigma_{i=1}^{n} \\alpha_i \\psi(x_i) \\; \\rangle = \\Sigma_{i,j=1}^{n} \\alpha_i \\alpha_j \\langle  \\; \\psi(x_i), \\psi(x_j) \\; \\rangle = \\Sigma_{i,j=1}^{n} \\alpha_i \\alpha_j k(x_i,x_j) = \\alpha^TK\\alpha$\n",
    "\n",
    "This is a quadratic form.\n",
    "\n",
    "#### Now we can kernalize some objective functions\n",
    "\n",
    "##### Kernalize SVM\n",
    "\n",
    "The SVM objective:  \n",
    "\n",
    "$min_{w\\in R^d} \\frac{1}{2} ||w||^2 + \\frac{c}{n} \\Sigma_{i=1}^{n} max(0, 1 - y_i[\\langle  \\; w, \\psi(x_i) \\; \\rangle])$\n",
    "\n",
    "Kernelizing yields:\n",
    "\n",
    "$min_{\\alpha\\in R^n} \\frac{1}{2} \\alpha^TK\\alpha + \\frac{c}{n} \\Sigma_{i=1}^{n} max(0, 1 - y_i(K\\alpha)_i)$\n",
    "\n",
    "SVM work very nicely with kernalizations, as many $\\alpha's$ are equal to 0. So not all n datapoints are needed for a prediction.\n",
    "\n",
    "##### Kernalize Ridge Regression\n",
    "\n",
    "Featurized ridge regression\n",
    "\n",
    "$min_{w\\in R^d} \\frac{1}{n} \\Sigma_{i=1}^{n} (\\langle  \\; w, \\psi(x_i) \\; \\rangle - y_i)^2 + \\lambda ||w||^2$\n",
    "\n",
    "Kernalized ridge Regression:\n",
    "\n",
    "$min_{\\alpha\\in R^n} \\frac{1}{n} ||K\\alpha - y||^2 + \\lambda\\alpha^TK\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with different kernels (linear, poly, rbf) and  flattened mfcc input vectors\n",
    "\n",
    "Using 5 fold Cross Validation to tune C value of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice of C:  10.0\n",
      "Cross-validation accuracy score estimate:  0.8483850931677018\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.001,0.01,0.1,1.0,10.0,100.0]\n",
    "\n",
    "acc_scores_rbf = []\n",
    "for c in c_values:\n",
    "    \n",
    "    clf = svm.SVC(C=c, kernel = 'rbf')\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "    m = scores.mean()\n",
    "    acc_scores_rbf.append(m)\n",
    "    \n",
    "index_max = max(range(len(acc_scores_rbf)), key=acc_scores_rbf.__getitem__) # get the index of hyperparameter with max accuracy \n",
    "    \n",
    "plt.plot(c_values, acc_scores_rbf)\n",
    "plt.show()\n",
    "h, s = c_values[index_max], max(acc_scores_rbf)\n",
    "print(\"Choice of C: \", h)\n",
    "print(\"Cross-validation accuracy score estimate: \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871244635193133"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=1, kernel = 'rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "metrics.accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=10, kernel = 'rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice of C:  10.0\n",
      "Cross-validation accuracy score estimate:  0.6952929085303187\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.001,0.01,0.1,1.0,10.0,100.0]\n",
    "\n",
    "acc_scores_poly = []\n",
    "for c in c_values:\n",
    "    \n",
    "    clf = svm.SVC(C=c, kernel = 'poly')\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    m = scores.mean()\n",
    "    acc_scores_poly.append(m)\n",
    "    \n",
    "index_max = max(range(len(acc_scores_poly)), key=acc_scores_poly.__getitem__) # get the index of hyperparameter with max accuracy \n",
    "    \n",
    "plt.plot(c_values, acc_scores_poly)\n",
    "plt.show()\n",
    "h, s = c_values[index_max], max(acc_scores_poly)\n",
    "print(\"Choice of C: \", h)\n",
    "print(\"Cross-validation accuracy score estimate: \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=10, kernel = 'poly')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "metrics.accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=10, kernel = 'poly')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice of C:  0.001\n",
      "Cross-validation accuracy score estimate:  0.7452723535457348\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.00001,0.0001,0.001,0.01,0.1,1]\n",
    "\n",
    "acc_scores_linear = []\n",
    "for c in c_values:\n",
    "    \n",
    "    clf = svm.SVC(C=c, kernel = 'linear')\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    m = scores.mean()\n",
    "    acc_scores_linear.append(m)\n",
    "    \n",
    "index_max = max(range(len(acc_scores_linear)), key=acc_scores_linear.__getitem__) # get the index of hyperparameter with max accuracy \n",
    "    \n",
    "plt.plot(c_values, acc_scores_linear)\n",
    "plt.show()\n",
    "h, s = c_values[index_max], max(acc_scores_linear)\n",
    "print(\"Choice of C: \", h)\n",
    "print(\"Cross-validation accuracy score estimate: \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9599427753934192"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=0.001, kernel = 'linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "metrics.accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=0.001, kernel = 'linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOcmHtlJiw0iBh08iZKWaxr",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1nfoUnuQctT7dUUB7t4If4MLrhbcULL6t",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
